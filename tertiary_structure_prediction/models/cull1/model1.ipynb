{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'tensorflow' from '/Users/jinli/anaconda3/lib/python3.6/site-packages/tensorflow/__init__.py'>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import tensorflow as tf\n",
    "import importlib\n",
    "importlib.reload(tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_path = \"../../data/cull%i/model_data/\" % 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "devtest_aa_dict = np.load(data_path + 'devtest_aa_dict.npy')[()]\n",
    "devtest_cmap_dict = np.load(data_path + 'devtest_cmap_dict.npy')[()]\n",
    "train_aa_dict = np.load(data_path + 'train_aa_dict.npy')[()]\n",
    "train_cmap_dict = np.load(data_path + 'train_cmap_dict.npy')[()]\n",
    "valid_aa_dict = np.load(data_path + 'valid_aa_dict.npy')[()]\n",
    "valid_cmap_dict = np.load(data_path + 'valid_cmap_dict.npy')[()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# devtest_aa_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from keras import backend as K\n",
    "# from keras.engine.topology import Layer\n",
    "# # from keras.layers import Layer\n",
    "\n",
    "# # Need to create my own outer product layer\n",
    "# class OuterConcat(Layer):\n",
    "#     def __init__(self, output_dim, **kwargs):\n",
    "#         self.output_dim = output_dim\n",
    "#         self.name = \"HII\"\n",
    "        \n",
    "#     def built(self, input_shape):\n",
    "#         # Create a trainable weight variable for this layer.\n",
    "#         self.kernel = self.add_weight(name='kernel', \n",
    "#                                       shape=(input_shape[1], self.output_dim),\n",
    "#                                       initializer='uniform',\n",
    "#                                       trainable=True)\n",
    "#         super(MyLayer, self).build(input_shape)  # Be sure to call this at the end\n",
    "        \n",
    "#     def call(self, x):\n",
    "#         return K.dot(x, self.kernel)\n",
    "    \n",
    "#     def compute_output_shape(self, input_shape):\n",
    "#         return (input_shape[0], self.output_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyLayer(tf.keras.layers.Layer):\n",
    "\n",
    "    def __init__(self, output_dim, **kwargs):\n",
    "        self.output_dim = output_dim\n",
    "        super(MyLayer, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        # Create a trainable weight variable for this layer.\n",
    "        self.kernel = self.add_weight(name='kernel', \n",
    "                                      shape=(input_shape[1], self.output_dim),\n",
    "                                      initializer='uniform',\n",
    "                                      trainable=True)\n",
    "        super(MyLayer, self).build(input_shape)  # Be sure to call this at the end\n",
    "\n",
    "    def call(self, x):\n",
    "        return K.dot(x, self.kernel)\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (input_shape[0], self.output_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seq2pairwise(x)\n",
    "# x = [1, 2, 3]\n",
    "# y = [4, 5, 6]\n",
    "# X, Y = tf.meshgrid(x, y)\n",
    "# X.get_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def seq2pairwise(incoming):\n",
    "    L = tf.shape(incoming)[1]\n",
    "    #save the indexes of each position\n",
    "    v = tf.range(0, L, 1)\n",
    "    i, j = tf.meshgrid(v, v)\n",
    "    m = (i+j)/2\n",
    "    #switch batch dim with L dim to put L at first\n",
    "    incoming2 = tf.transpose(incoming, perm=[1, 0, 2])\n",
    "    #full matrix i with element in incomming2 indexed i[i][j]\n",
    "    out1 = tf.nn.embedding_lookup(incoming2, i)\n",
    "    out2 = tf.nn.embedding_lookup(incoming2, j)\n",
    "    out3 = tf.nn.embedding_lookup(incoming2, m)\n",
    "    #concatante final feature dim together\n",
    "    out = tf.concat([out1, out2, out3], axis=3)\n",
    "    #return to original dims\n",
    "    output = tf.transpose(out, perm=[2, 0, 1, 3])\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<__main__.MyDenseLayer object at 0x182c74c2b0>\n",
      "Tensor(\"my_dense_layer/MatMul:0\", shape=(10, 10), dtype=float32)\n",
      "[<tf.Variable 'my_dense_layer/kernel:0' shape=(5, 10) dtype=float32>]\n"
     ]
    }
   ],
   "source": [
    "class MyDenseLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, num_outputs):\n",
    "        super(MyDenseLayer, self).__init__()\n",
    "        self.num_outputs = num_outputs\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.kernel = self.add_variable(\n",
    "            \"kernel\",\n",
    "            shape=[int(input_shape[-1]),\n",
    "                   self.num_outputs])\n",
    "\n",
    "    def call(self, input):\n",
    "        return tf.matmul(input, self.kernel)\n",
    "\n",
    "\n",
    "layer = MyDenseLayer(10)\n",
    "print(layer)\n",
    "print(layer(tf.zeros([10, 5])))\n",
    "print(layer.trainable_variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OuterProduct(tf.keras.layers.Layer):\n",
    "    def __init__(self):\n",
    "        super(OuterProduct, self).__init__()\n",
    "    \n",
    "#     def build(self, input_shape):\n",
    "#         self.kernel = self.add_variable(\n",
    "#             \"kernel\",\n",
    "#             shape=[\n",
    "#                 (input_shape[0]), \n",
    "#                 (input_shape[1]),\n",
    "#                 (input_shape[1]),\n",
    "#                 int(input_shape[2]) * 3\n",
    "#                   ]\n",
    "#         )\n",
    "    def call(self, incoming):\n",
    "        \n",
    "        L = tf.shape(incoming)[1]\n",
    "        \n",
    "        #save the indexes of each position\n",
    "        v = tf.range(0, L, 1)\n",
    "        \n",
    "        i, j = tf.meshgrid(v, v)\n",
    "        \n",
    "        m = tf.cast((i+j)/2, tf.int32)\n",
    "        \n",
    "        #switch batch dim with L dim to put L at first\n",
    "        incoming2 = tf.transpose(incoming, perm=[1, 0, 2])\n",
    "        \n",
    "        #full matrix i with element in incomming2 indexed i[i][j]\n",
    "        out1 = tf.nn.embedding_lookup(incoming2, i)\n",
    "        out2 = tf.nn.embedding_lookup(incoming2, j)\n",
    "        out3 = tf.nn.embedding_lookup(incoming2, m)\n",
    "        \n",
    "        #concatante final feature dim together\n",
    "        out = tf.concat([out1, out2, out3], axis=3)\n",
    "        #return to original dims\n",
    "        output = tf.transpose(out, perm=[2, 0, 1, 3])\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class ResidualBlock1D(tf.keras.layers.Layer):\n",
    "    \"\"\"\n",
    "    All the layers in the residual block will have the \n",
    "    same number of features and stride.\n",
    "    There are two layers in this block\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, stride):\n",
    "#         self.size = size\n",
    "        self.stride = stride\n",
    "        super(ResidualBlock1D, self).__init__()\n",
    "        \n",
    "\n",
    "    def call(self, x):\n",
    "        size = int (x.shape[-1])\n",
    "        y = tf.keras.layers.Conv1D(\n",
    "            size,\n",
    "            self.stride,\n",
    "            activation='relu',\n",
    "        )(x)\n",
    "        y = tf.keras.layers.Conv1D(\n",
    "            size,\n",
    "            self.stride,\n",
    "            activation='relu',\n",
    "        )(y)\n",
    "        \n",
    "        y = tf.keras.layers.add([y, x])\n",
    "        \n",
    "        return y\n",
    "    \n",
    "class ResidualBlock2D(tf.keras.layers.Layer):\n",
    "    \"\"\"\n",
    "    All the layers in the residual block will have the \n",
    "    same number of features and stride.\n",
    "    There are two layers in this block\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, stride):\n",
    "#         self.size = size\n",
    "        self.stride = stride\n",
    "        super(ResidualBlock2D, self).__init__()\n",
    "        \n",
    "\n",
    "    def call(self, x):\n",
    "        size = int (x.shape[-1])\n",
    "        y = tf.keras.layers.Conv2D(\n",
    "            size,\n",
    "            self.stride,\n",
    "            activation='relu',\n",
    "            padding='same'\n",
    "        )(x)\n",
    "        y = tf.keras.layers.Conv2D(\n",
    "            size,\n",
    "            self.stride,\n",
    "            activation='relu',\n",
    "            padding='same'\n",
    "        )(y)\n",
    "        \n",
    "        y = tf.keras.layers.add([y, x])\n",
    "        \n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_8 (InputLayer)         (None, None, 20)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_28 (Conv1D)           (None, None, 40)          840       \n",
      "_________________________________________________________________\n",
      "conv1d_29 (Conv1D)           (None, None, 60)          2460      \n",
      "_________________________________________________________________\n",
      "residual_block1d_7 (Residual (None, None, 60)          0         \n",
      "_________________________________________________________________\n",
      "outer_product_7 (OuterProduc (None, None, None, 180)   0         \n",
      "_________________________________________________________________\n",
      "residual_block2d_7 (Residual (None, None, None, 180)   0         \n",
      "_________________________________________________________________\n",
      "conv2d_23 (Conv2D)           (None, None, None, 2)     362       \n",
      "=================================================================\n",
      "Total params: 3,662\n",
      "Trainable params: 3,662\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# from keras.models import Sequential\n",
    "\n",
    "# model = Sequential()\n",
    "\n",
    "# from keras import Input\n",
    "\n",
    "# from keras.models import Model\n",
    "# from tensorflow.keras.model import Model\n",
    "# from keras import layers\n",
    "# from tf.keras.layers\n",
    "\n",
    "input_tensor = tf.keras.Input(shape=(None, 20))\n",
    "x = tf.keras.layers.Conv1D(\n",
    "    40,\n",
    "    1,\n",
    "    activation='relu',\n",
    ")(input_tensor)\n",
    "\n",
    "x = tf.keras.layers.Conv1D(\n",
    "    60,\n",
    "    1,\n",
    "    activation='relu',\n",
    ")(x)\n",
    "\n",
    "x = ResidualBlock1D(1)(x)\n",
    "\n",
    "\"\"\"\n",
    "EDIT: did not have to do this lol.\n",
    "Keras 2.2.4\n",
    "\n",
    "To make this work, I had to go to:\n",
    "/Users/jinli/anaconda3/lib/python3.6/site-packages/tensorflow/python/keras/engine/base_layer.py\n",
    "\n",
    "and change on line: 1749\n",
    "layer.outbound_nodes.append(self)\n",
    "\n",
    "to\n",
    "\n",
    "layer._outbound_nodes.append(self)\n",
    "\"\"\"\n",
    "\n",
    "x = OuterProduct()(x)\n",
    "x = ResidualBlock2D(1)(x)\n",
    "# x = tf.keras.layers.Dense(128, activation='relu')(x)\n",
    "\n",
    "\n",
    "x = tf.keras.layers.Conv2D(2, 1, activation='relu', padding='same')(x)\n",
    "# x = tf.keras.layers.Flatten()(x)\n",
    "model = tf.keras.models.Model(\n",
    "    input_tensor,\n",
    "    x\n",
    ")\n",
    "\n",
    "# x = MyDenseLayer(10)(x)\n",
    "\n",
    "# third column is the number of feature maps\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jinli/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:112: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      " 4/10 [===========>..................] - ETA: 4s - loss: 0.7478"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "logits and labels must have the same first dimension, got logits shape [24649,2] and labels shape [24336]\n\t [[{{node loss_24/conv2d_23_loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits}} = SparseSoftmaxCrossEntropyWithLogits[T=DT_FLOAT, Tlabels=DT_INT64, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](loss_24/conv2d_23_loss/Reshape_1, loss_24/conv2d_23_loss/Cast)]]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-107-880eeabce3cf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0maa_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_aa_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_cmap_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m )\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   2175\u001b[0m         \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2176\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2177\u001b[0;31m         initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   2178\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2179\u001b[0m   def evaluate_generator(self,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    174\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m         outs = model.train_on_batch(\n\u001b[0;32m--> 176\u001b[0;31m             x, y, sample_weight=sample_weight, class_weight=class_weight)\n\u001b[0m\u001b[1;32m    177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1938\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1939\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1940\u001b[0;31m       \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1941\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1942\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2984\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2985\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[0;32m-> 2986\u001b[0;31m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[1;32m   2987\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2988\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[1;32m    526\u001b[0m             \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    527\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 528\u001b[0;31m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[1;32m    529\u001b[0m     \u001b[0;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m     \u001b[0;31m# as there is a reference to status from this from the traceback due to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: logits and labels must have the same first dimension, got logits shape [24649,2] and labels shape [24336]\n\t [[{{node loss_24/conv2d_23_loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits}} = SparseSoftmaxCrossEntropyWithLogits[T=DT_FLOAT, Tlabels=DT_INT64, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](loss_24/conv2d_23_loss/Reshape_1, loss_24/conv2d_23_loss/Cast)]]"
     ]
    }
   ],
   "source": [
    "model.compile(\n",
    "    optimizer=tf.train.AdamOptimizer(0.001),\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    sample_weight_mode=\"temporal\"\n",
    ")\n",
    "model.fit_generator(\n",
    "    aa_generator(train_aa_dict, train_cmap_dict),\n",
    "    steps_per_epoch=10, \n",
    "    epochs=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = OuterProduct()\n",
    "test1 = test(tf.zeros([4, 5, 6]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "156.0"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# int (x.shape[-1])\n",
    "\n",
    "# output and input from preprocessing probably doesn't align\n",
    "import math\n",
    "math.sqrt(24649)\n",
    "math.sqrt(24336)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test1.shape\n",
    "tf.VERSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zeros = tf.zeros([10, 5, 6])\n",
    "type(test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model1 = tf.keras.models.Sequential([\n",
    "#     tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "#     tf.keras.layers.Dense(128, activation='relu'),\n",
    "#     tf.keras.layers.Dropout(0.2),\n",
    "#     tf.keras.layers.Dense(10, activation='softmax'),\n",
    "# #     MyDenseLayer(10),\n",
    "# #     test,\n",
    "# ])\n",
    "\n",
    "# # model2 = tf.keras.models.Sequential([\n",
    "# #     test()\n",
    "# # ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model2.summary()\n",
    "model1.compile(\n",
    "    optimizer=tf.train.AdamOptimizer(0.001),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1 + 3 / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keras import models\n",
    "# from keras import layers\n",
    "# network = tf.keras.models.Sequential()\n",
    "# network.add(tf.keras.layers.Dense(512, activation='relu', input_shape=(28 * 28,)))\n",
    "# network.add(tf.keras.layers.Dense(10, activation='softmax'))\n",
    "\n",
    "# network.compile(optimizer='rmsprop',\n",
    "#                 loss='categorical_crossentropy',\n",
    "#                 metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "# from tensorflow.keras import layers\n",
    "\n",
    "# model = tf.keras.Sequential([\n",
    "#     # Adds a densely-connected layer with 64 units to the model:\n",
    "#     layers.Dense(64, activation='relu', input_shape=(32,)),\n",
    "#     # Add another:\n",
    "#     layers.Dense(64, activation='relu'),\n",
    "#     # Add a softmax layer with 10 output units:\n",
    "#     layers.Dense(10, activation='softmax')])\n",
    "\n",
    "# model.compile(\n",
    "#     optimizer=tf.train.AdamOptimizer(0.001),\n",
    "#     loss='categorical_crossentropy',\n",
    "#     metrics=['accuracy']\n",
    "# )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "def aa_generator(x, y):\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    inputs = x.copy()\n",
    "    outputs = y.copy()\n",
    "    keys = set (x.keys())\n",
    "#     print(keys)\n",
    "    while True:\n",
    "        try:\n",
    "            key = random.sample(keys, 1)[0]\n",
    "            keys.remove(key)\n",
    "            \n",
    "            one_hot_aa = x[key]\n",
    "            one_hot_aa = np.reshape(one_hot_aa, (1,) + one_hot_aa.shape)\n",
    "            cmap = y[key]\n",
    "            cmap = np.reshape(cmap, (1,) + cmap.shape + (1,))\n",
    "            yield one_hot_aa, cmap\n",
    "\n",
    "#             yield key\n",
    "        except ValueError:\n",
    "            # if out of keys, reinsert back the keys\n",
    "            inputs = x.copy()\n",
    "            outputs = y.copy()\n",
    "            keys = set (x.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "keys = []\n",
    "for item in aa_generator(train_aa_dict, train_cmap_dict):\n",
    "    if i == 142:\n",
    "        break\n",
    "    keys.append(item)\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "140"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train_aa_dict['1']\n",
    "# keys\n",
    "# len (aa_generator)\n",
    "len (set (keys))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 366, 20)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# len (train_aa_dict.keys())\n",
    "array = train_aa_dict['16vp']#.reshape(-1)\n",
    "np.reshape(array, (1,) + array.shape).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
