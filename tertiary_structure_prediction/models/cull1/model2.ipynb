{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'plotting' from '../model_functions/plotting.py'>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, '../model_functions')\n",
    "import plotting as pl\n",
    "import importlib\n",
    "# importlib.reload(pl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_path = \"../../data/cull%i/model_data/\" % 1\n",
    "\n",
    "train_aa_dict = np.load(data_path + 'train_aa_dict.npy')[()]\n",
    "train_cmap_dict = np.load(data_path + 'train_cmap_dict.npy')[()]\n",
    "valid_aa_dict = np.load(data_path + 'valid_aa_dict.npy')[()]\n",
    "valid_cmap_dict = np.load(data_path + 'valid_cmap_dict.npy')[()]\n",
    "devtest_aa_dict = np.load(data_path + 'devtest_aa_dict.npy')[()]\n",
    "devtest_cmap_dict = np.load(data_path + 'devtest_cmap_dict.npy')[()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "139"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_aa_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Special Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# class OuterProduct(tf.keras.layers.Layer):\n",
    "#     \"\"\"\n",
    "#     Given a layer of size (B, L, N), create \n",
    "#     a layer of size (B, L, L, 3N).\n",
    "#     If we have {v1, ..., vm},\n",
    "#     for the i, j entry, we have (vi, v((i+j)/2), vj).\n",
    "#     \"\"\"\n",
    "\n",
    "#     def __init__(self):\n",
    "#         super(OuterProduct, self).__init__()\n",
    "\n",
    "#     def call(self, incoming):\n",
    "#         \"\"\"\n",
    "#         Create the layer.\n",
    "\n",
    "#         :param incoming: tensor of size (B, L, N)\n",
    "#         :type  incoming: tensorflow.python.framework.ops.Tensor\n",
    "#         :returns: tensor of size (B, L, L, 3N)\n",
    "#         :rtype:   tensorflow.python.framework.ops.Tensor\n",
    "#         \"\"\"\n",
    "\n",
    "#         L = tf.shape(incoming)[1]\n",
    "#         # save the indexes of each position\n",
    "#         v = tf.range(0, L, 1)\n",
    "\n",
    "#         i, j = tf.meshgrid(v, v)\n",
    "\n",
    "#         m = tf.cast((i+j)/2, tf.int32)\n",
    "\n",
    "#         # switch batch dim with L dim to put L at first\n",
    "#         incoming2 = tf.transpose(incoming, perm=[1, 0, 2])\n",
    "\n",
    "#         # full matrix i with element in incomming2 indexed i[i][j]\n",
    "#         out1 = tf.nn.embedding_lookup(incoming2, i)\n",
    "#         out2 = tf.nn.embedding_lookup(incoming2, j)\n",
    "#         out3 = tf.nn.embedding_lookup(incoming2, m)\n",
    "\n",
    "#         # concatanate final feature dim together\n",
    "#         out = tf.concat([out1, out2, out3], axis=3)\n",
    "#         # return to original dims\n",
    "#         output = tf.transpose(\n",
    "#             out,\n",
    "#             perm=[2, 0, 1, 3],\n",
    "#             name=\"outer_product\"\n",
    "#         )\n",
    "#         return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.5"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "5.5 % 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def residual_conv_block(\n",
    "#         x,\n",
    "#         convnet,\n",
    "#         stride,\n",
    "#         num_layers,\n",
    "#         regularizer=None,\n",
    "#         activation=\"relu\",\n",
    "#         padding=\"same\"):\n",
    "#     \"\"\"\n",
    "#     Create a residual convolution block, either \n",
    "#     in 1 or 2 dimensions.\n",
    "\n",
    "#     :param x: \n",
    "#     :type x:  \n",
    "#     :param convnet: indicates which type of layer to use\n",
    "#     :type  convnet: string\n",
    "#     :param stride: stride\n",
    "#     :type  stride: int\n",
    "#     :param num_layers: number of layers for the entire residual network\n",
    "#     :type  num_layers: int\n",
    "#     :param regularizer: \n",
    "#     :type  regularizer: \n",
    "#     :param activation: \n",
    "#     :type  activation: str\n",
    "#     :param padding:\n",
    "#     :type  padding: str\n",
    "#     :returns: result of the residual network\n",
    "#     :rtype:   tensorflow.python.framework.ops.Tensor\n",
    "#     \"\"\"\n",
    "\n",
    "#     size = int(x.shape[-1])\n",
    "#     y = x\n",
    "\n",
    "#     if num_layers % 2 != 0:\n",
    "#         raise ValueError(\"The number of layers must be even\")\n",
    "\n",
    "#     def one_dim_block(x, i):\n",
    "#         \"\"\"\n",
    "#         Create the duo layer for conv1d.\n",
    "\n",
    "#         :param x: input\n",
    "#         :type  x: tensorflow.python.framework.ops.Tensor\n",
    "#         :param i: position of that duo layer\n",
    "#         :type  i: int\n",
    "#         :returns: \n",
    "#         :rtype:   tensorflow.python.framework.ops.Tensor\n",
    "#         \"\"\"\n",
    "\n",
    "#         i += 1\n",
    "#         z = tf.keras.layers.Conv1D(\n",
    "#             size,\n",
    "#             stride,\n",
    "#             activation=activation,\n",
    "#             padding=padding,\n",
    "#             kernel_regularizer=regularizer,\n",
    "#             name=convnet + \"_layer{}a\".format(i),\n",
    "#         )(x)\n",
    "#         z = tf.keras.layers.BatchNormalization(\n",
    "#             name=convnet + \"_batch_norm{}a\".format(i),\n",
    "#         )(z)\n",
    "\n",
    "#         z = tf.keras.layers.Conv1D(\n",
    "#             size,\n",
    "#             stride,\n",
    "#             activation=activation,\n",
    "#             padding=padding,\n",
    "#             kernel_regularizer=regularizer,\n",
    "#             name=convnet + \"_layer{}b\".format(i),\n",
    "#         )(z)\n",
    "#         z = tf.keras.layers.BatchNormalization(\n",
    "#             name=convnet + \"_batch_norm{}b\".format(i),\n",
    "#         )(z)\n",
    "\n",
    "#         z = tf.keras.layers.add(\n",
    "#             [z, x],\n",
    "#             name=convnet + \"_residual_block{}\".format(i)\n",
    "#         )\n",
    "\n",
    "#         return z\n",
    "\n",
    "#     def two_dim_block(x, i):\n",
    "#         \"\"\"\n",
    "#         Create the duo layer for conv2d.\n",
    "\n",
    "#         :param x: input\n",
    "#         :type  x: tensorflow.python.framework.ops.Tensor\n",
    "#         :param i: position of that duo layer\n",
    "#         :type  i: int\n",
    "#         :returns: \n",
    "#         :rtype:   tensorflow.python.framework.ops.Tensor\n",
    "#         \"\"\"\n",
    "\n",
    "#         i += 1\n",
    "#         z = tf.keras.layers.Conv2D(\n",
    "#             size,\n",
    "#             stride,\n",
    "#             activation=activation,\n",
    "#             padding=padding,\n",
    "#             kernel_regularizer=regularizer,\n",
    "#             name=convnet + \"_layer{}a\".format(i),\n",
    "#         )(x)\n",
    "#         z = tf.keras.layers.BatchNormalization(\n",
    "#             name=convnet + \"_batch_norm{}a\".format(i),\n",
    "#         )(z)\n",
    "\n",
    "#         z = tf.keras.layers.Conv2D(\n",
    "#             size,\n",
    "#             stride,\n",
    "#             activation=activation,\n",
    "#             padding=padding,\n",
    "#             kernel_regularizer=regularizer,\n",
    "#             name=convnet + \"_layer{}b\".format(i),\n",
    "#         )(z)\n",
    "#         z = tf.keras.layers.BatchNormalization(\n",
    "#             name=convnet + \"_batch_norm{}b\".format(i),\n",
    "#         )(z)\n",
    "\n",
    "#         z = tf.keras.layers.add(\n",
    "#             [z, x],\n",
    "#             name=convnet + \"_residual_block{}\".format(i)\n",
    "#         )\n",
    "\n",
    "#         return z\n",
    "\n",
    "#     if convnet == \"1d_convnet\":\n",
    "#         for i in range(int(num_layers / 2)):\n",
    "#             y = one_dim_block(y, i)\n",
    "\n",
    "#         name = \"convnet_1d\"\n",
    "\n",
    "#     elif convnet == \"2d_convnet\":\n",
    "#         for i in range(int(num_layers / 2)):\n",
    "#             y = two_dim_block(y, i)\n",
    "#         name = \"convnet_2d\"\n",
    "\n",
    "#     else:\n",
    "#         raise ValueError(\"Not an available convnet dimension\")\n",
    "\n",
    "#     return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# inception V3 module\n",
    "\n",
    "def inception_module (x):\n",
    "    \"\"\"\n",
    "    Create the inception V3 module\n",
    "    \n",
    "    :param x: Tensor input continuing from the chain\n",
    "    :type  x: tensorflow.python.framework.ops.Tensor\n",
    "    \n",
    "    :return: The concatenated output of the four branches\n",
    "    :rtype:  tensorflow.python.framework.ops.Tensor\n",
    "    \"\"\"\n",
    "    \n",
    "    branch_a = layers.Conv2D(\n",
    "        128,\n",
    "        1,\n",
    "        activation='relu',\n",
    "        strides=2,\n",
    "        padding=\"same\"\n",
    "    )(x)\n",
    "\n",
    "    branch_b = layers.Conv2D(\n",
    "        128,\n",
    "        1,\n",
    "        activation='relu'\n",
    "    )(x)\n",
    "    branch_b = layers.Conv2D(\n",
    "        128,\n",
    "        3,\n",
    "        activation='relu',\n",
    "        strides=2,\n",
    "        padding=\"same\"\n",
    "    )(branch_b)\n",
    "\n",
    "    branch_c = layers.AveragePooling2D(\n",
    "        3,\n",
    "        strides=2,\n",
    "        padding=\"same\"\n",
    "    )(x)\n",
    "    branch_c = layers.Conv2D(\n",
    "        128,\n",
    "        3,\n",
    "        activation='relu',\n",
    "        padding=\"same\"\n",
    "    )(branch_c)\n",
    "\n",
    "    branch_d = layers.Conv2D(\n",
    "        128,\n",
    "        1,\n",
    "        activation='relu'\n",
    "    )(x)\n",
    "    branch_d = layers.Conv2D(\n",
    "        128,\n",
    "        3,\n",
    "        activation='relu',\n",
    "        padding=\"same\"\n",
    "    )(branch_d)\n",
    "    branch_d = layers.Conv2D(\n",
    "        128,\n",
    "        3,\n",
    "        activation='relu',\n",
    "        strides=2,\n",
    "        padding=\"same\"\n",
    "    )(branch_d)\n",
    "\n",
    "    output = layers.concatenate(\n",
    "        [branch_a, branch_b, branch_c, branch_d],\n",
    "        name=\"Inception_V3\"\n",
    "    )\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "\n",
    "# def aa_generator(x, y):\n",
    "#     \"\"\"\n",
    "#     Generator for feeding a single instance of an \n",
    "#     input and an output.\n",
    "#     The generator is reset when all elements are used.\n",
    "\n",
    "#     :param: input\n",
    "#     :type:  dict\n",
    "#     :param: label\n",
    "#     :type:  dict\n",
    "#     :returns: a single instance of input and label\n",
    "#     :rtype:   (numpy array, numpy array)\n",
    "#     \"\"\"\n",
    "\n",
    "#     inputs = x.copy()\n",
    "#     outputs = y.copy()\n",
    "#     keys = set(x.keys())\n",
    "\n",
    "#     while True:\n",
    "#         try:\n",
    "#             key = random.sample(keys, 1)[0]\n",
    "#             keys.remove(key)\n",
    "\n",
    "#             one_hot_aa = x[key]\n",
    "#             one_hot_aa = np.reshape(one_hot_aa, (1,) + one_hot_aa.shape)\n",
    "#             cmap = y[key]\n",
    "#             cmap = np.reshape(cmap, (1,) + cmap.shape + (1,))\n",
    "#             yield one_hot_aa, cmap\n",
    "\n",
    "#         except ValueError:\n",
    "#             # if out of keys, reinsert back the keys\n",
    "#             inputs = x.copy()\n",
    "#             outputs = y.copy()\n",
    "#             keys = set(x.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What the paper said:\n",
    "    \n",
    "    3-state second- ary structure and 3-state solvent accessibility\n",
    "    added onto to the amino acid \n",
    "    \n",
    "    ReLU activation after each layer.\n",
    "    In the residual network, their number of features of the \n",
    "    next layer is greater than the one below it, so they had to padd\n",
    "    the previous layer with zeros to allow adding. Not doing this\n",
    "    Batch normalization before activation layer \n",
    "    (but did not say whether this was after or before the convolution layer)\n",
    "    window size for 1d residual network was 17\n",
    "    window size for 2d residual network was either 3 or 5\n",
    "    6 convnet layers for first residual network (fixed)\n",
    "    for second residual network: 60 hidden neurons for each layer, 60 conv layers (varied)\n",
    "\n",
    "    The paper also assigned contacts with higher weights than non-contacts\n",
    "    for loss function. No clue how to do this though.\n",
    "    The paper never mentioned dropout, but we can try anyways.\n",
    "    \n",
    "    Included pairwise features \n",
    "    (mutual information, \n",
    "    the EC information calculated by CCMpred, \n",
    "    and pair- wise contact potential)\n",
    "    \n",
    "    loss function:\n",
    "    negative log-likelihood averaged over all the residue pairs of the training proteins.\n",
    "    assign a larger weight to the residue pairs forming a contact. \n",
    "    The weight is assigned such that the total weight assigned to contacts \n",
    "    is approximately 1/8 of the number of non-contacts in the training set.\n",
    "    \n",
    "    l2 norm regularization\n",
    "    stochastic gradient descent\n",
    "    20-30 epochs (each epoch scans through all the training proteins exactly once)\n",
    "    \n",
    "    can have mini-batches, but they sorted the training set and then grouped batches\n",
    "    by related size. Then they did some extra padding to make sure all proteins\n",
    "    in batch size were the same.\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_layer (InputLayer)        (None, None, 20)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "1d_convnet_layer0a (Conv1D)     (None, None, 20)     6820        input_layer[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "1d_convnet_batch_norm0a (BatchN (None, None, 20)     80          1d_convnet_layer0a[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "1d_convnet_layer0b (Conv1D)     (None, None, 20)     6820        1d_convnet_batch_norm0a[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "1d_convnet_batch_norm0b (BatchN (None, None, 20)     80          1d_convnet_layer0b[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "1d_convnet_residual_block0 (Add (None, None, 20)     0           1d_convnet_batch_norm0b[0][0]    \n",
      "                                                                 input_layer[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "1d_convnet_layer1a (Conv1D)     (None, None, 20)     6820        1d_convnet_residual_block0[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "1d_convnet_batch_norm1a (BatchN (None, None, 20)     80          1d_convnet_layer1a[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "1d_convnet_layer1b (Conv1D)     (None, None, 20)     6820        1d_convnet_batch_norm1a[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "1d_convnet_batch_norm1b (BatchN (None, None, 20)     80          1d_convnet_layer1b[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "1d_convnet_residual_block1 (Add (None, None, 20)     0           1d_convnet_batch_norm1b[0][0]    \n",
      "                                                                 1d_convnet_residual_block0[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "1d_convnet_layer2a (Conv1D)     (None, None, 20)     6820        1d_convnet_residual_block1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "1d_convnet_batch_norm2a (BatchN (None, None, 20)     80          1d_convnet_layer2a[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "1d_convnet_layer2b (Conv1D)     (None, None, 20)     6820        1d_convnet_batch_norm2a[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "1d_convnet_batch_norm2b (BatchN (None, None, 20)     80          1d_convnet_layer2b[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "1d_convnet_residual_block2 (Add (None, None, 20)     0           1d_convnet_batch_norm2b[0][0]    \n",
      "                                                                 1d_convnet_residual_block1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "outer_product_28 (OuterProduct) (None, None, None, 6 0           1d_convnet_residual_block2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "2d_convnet_layer0a (Conv2D)     (None, None, None, 6 32460       outer_product_28[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "2d_convnet_batch_norm0a (BatchN (None, None, None, 6 240         2d_convnet_layer0a[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "2d_convnet_layer0b (Conv2D)     (None, None, None, 6 32460       2d_convnet_batch_norm0a[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "2d_convnet_batch_norm0b (BatchN (None, None, None, 6 240         2d_convnet_layer0b[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "2d_convnet_residual_block0 (Add (None, None, None, 6 0           2d_convnet_batch_norm0b[0][0]    \n",
      "                                                                 outer_product_28[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "2d_convnet_layer1a (Conv2D)     (None, None, None, 6 32460       2d_convnet_residual_block0[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "2d_convnet_batch_norm1a (BatchN (None, None, None, 6 240         2d_convnet_layer1a[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "2d_convnet_layer1b (Conv2D)     (None, None, None, 6 32460       2d_convnet_batch_norm1a[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "2d_convnet_batch_norm1b (BatchN (None, None, None, 6 240         2d_convnet_layer1b[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "2d_convnet_residual_block1 (Add (None, None, None, 6 0           2d_convnet_batch_norm1b[0][0]    \n",
      "                                                                 2d_convnet_residual_block0[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "2d_convnet_layer2a (Conv2D)     (None, None, None, 6 32460       2d_convnet_residual_block1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "2d_convnet_batch_norm2a (BatchN (None, None, None, 6 240         2d_convnet_layer2a[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "2d_convnet_layer2b (Conv2D)     (None, None, None, 6 32460       2d_convnet_batch_norm2a[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "2d_convnet_batch_norm2b (BatchN (None, None, None, 6 240         2d_convnet_layer2b[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "2d_convnet_residual_block2 (Add (None, None, None, 6 0           2d_convnet_batch_norm2b[0][0]    \n",
      "                                                                 2d_convnet_residual_block1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "2d_convnet_layer3a (Conv2D)     (None, None, None, 6 32460       2d_convnet_residual_block2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "2d_convnet_batch_norm3a (BatchN (None, None, None, 6 240         2d_convnet_layer3a[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "2d_convnet_layer3b (Conv2D)     (None, None, None, 6 32460       2d_convnet_batch_norm3a[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "2d_convnet_batch_norm3b (BatchN (None, None, None, 6 240         2d_convnet_layer3b[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "2d_convnet_residual_block3 (Add (None, None, None, 6 0           2d_convnet_batch_norm3b[0][0]    \n",
      "                                                                 2d_convnet_residual_block2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "2d_convnet_layer4a (Conv2D)     (None, None, None, 6 32460       2d_convnet_residual_block3[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "2d_convnet_batch_norm4a (BatchN (None, None, None, 6 240         2d_convnet_layer4a[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "2d_convnet_layer4b (Conv2D)     (None, None, None, 6 32460       2d_convnet_batch_norm4a[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "2d_convnet_batch_norm4b (BatchN (None, None, None, 6 240         2d_convnet_layer4b[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "2d_convnet_residual_block4 (Add (None, None, None, 6 0           2d_convnet_batch_norm4b[0][0]    \n",
      "                                                                 2d_convnet_residual_block3[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "2d_convnet_layer5a (Conv2D)     (None, None, None, 6 32460       2d_convnet_residual_block4[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "2d_convnet_batch_norm5a (BatchN (None, None, None, 6 240         2d_convnet_layer5a[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "2d_convnet_layer5b (Conv2D)     (None, None, None, 6 32460       2d_convnet_batch_norm5a[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "2d_convnet_batch_norm5b (BatchN (None, None, None, 6 240         2d_convnet_layer5b[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "2d_convnet_residual_block5 (Add (None, None, None, 6 0           2d_convnet_batch_norm5b[0][0]    \n",
      "                                                                 2d_convnet_residual_block4[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "2d_convnet_layer6a (Conv2D)     (None, None, None, 6 32460       2d_convnet_residual_block5[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "2d_convnet_batch_norm6a (BatchN (None, None, None, 6 240         2d_convnet_layer6a[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "2d_convnet_layer6b (Conv2D)     (None, None, None, 6 32460       2d_convnet_batch_norm6a[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "2d_convnet_batch_norm6b (BatchN (None, None, None, 6 240         2d_convnet_layer6b[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "2d_convnet_residual_block6 (Add (None, None, None, 6 0           2d_convnet_batch_norm6b[0][0]    \n",
      "                                                                 2d_convnet_residual_block5[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "2d_convnet_layer7a (Conv2D)     (None, None, None, 6 32460       2d_convnet_residual_block6[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "2d_convnet_batch_norm7a (BatchN (None, None, None, 6 240         2d_convnet_layer7a[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "2d_convnet_layer7b (Conv2D)     (None, None, None, 6 32460       2d_convnet_batch_norm7a[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "2d_convnet_batch_norm7b (BatchN (None, None, None, 6 240         2d_convnet_layer7b[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "2d_convnet_residual_block7 (Add (None, None, None, 6 0           2d_convnet_batch_norm7b[0][0]    \n",
      "                                                                 2d_convnet_residual_block6[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "2d_convnet_layer8a (Conv2D)     (None, None, None, 6 32460       2d_convnet_residual_block7[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "2d_convnet_batch_norm8a (BatchN (None, None, None, 6 240         2d_convnet_layer8a[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "2d_convnet_layer8b (Conv2D)     (None, None, None, 6 32460       2d_convnet_batch_norm8a[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "2d_convnet_batch_norm8b (BatchN (None, None, None, 6 240         2d_convnet_layer8b[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "2d_convnet_residual_block8 (Add (None, None, None, 6 0           2d_convnet_batch_norm8b[0][0]    \n",
      "                                                                 2d_convnet_residual_block7[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "2d_convnet_layer9a (Conv2D)     (None, None, None, 6 32460       2d_convnet_residual_block8[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "2d_convnet_batch_norm9a (BatchN (None, None, None, 6 240         2d_convnet_layer9a[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "2d_convnet_layer9b (Conv2D)     (None, None, None, 6 32460       2d_convnet_batch_norm9a[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "2d_convnet_batch_norm9b (BatchN (None, None, None, 6 240         2d_convnet_layer9b[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "2d_convnet_residual_block9 (Add (None, None, None, 6 0           2d_convnet_batch_norm9b[0][0]    \n",
      "                                                                 2d_convnet_residual_block8[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "2d_convnet_layer10a (Conv2D)    (None, None, None, 6 32460       2d_convnet_residual_block9[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "2d_convnet_batch_norm10a (Batch (None, None, None, 6 240         2d_convnet_layer10a[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "2d_convnet_layer10b (Conv2D)    (None, None, None, 6 32460       2d_convnet_batch_norm10a[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "2d_convnet_batch_norm10b (Batch (None, None, None, 6 240         2d_convnet_layer10b[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "2d_convnet_residual_block10 (Ad (None, None, None, 6 0           2d_convnet_batch_norm10b[0][0]   \n",
      "                                                                 2d_convnet_residual_block9[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "2d_convnet_layer11a (Conv2D)    (None, None, None, 6 32460       2d_convnet_residual_block10[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "2d_convnet_batch_norm11a (Batch (None, None, None, 6 240         2d_convnet_layer11a[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "2d_convnet_layer11b (Conv2D)    (None, None, None, 6 32460       2d_convnet_batch_norm11a[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "2d_convnet_batch_norm11b (Batch (None, None, None, 6 240         2d_convnet_layer11b[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "2d_convnet_residual_block11 (Ad (None, None, None, 6 0           2d_convnet_batch_norm11b[0][0]   \n",
      "                                                                 2d_convnet_residual_block10[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "2d_convnet_layer12a (Conv2D)    (None, None, None, 6 32460       2d_convnet_residual_block11[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "2d_convnet_batch_norm12a (Batch (None, None, None, 6 240         2d_convnet_layer12a[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "2d_convnet_layer12b (Conv2D)    (None, None, None, 6 32460       2d_convnet_batch_norm12a[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "2d_convnet_batch_norm12b (Batch (None, None, None, 6 240         2d_convnet_layer12b[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "2d_convnet_residual_block12 (Ad (None, None, None, 6 0           2d_convnet_batch_norm12b[0][0]   \n",
      "                                                                 2d_convnet_residual_block11[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "2d_convnet_layer13a (Conv2D)    (None, None, None, 6 32460       2d_convnet_residual_block12[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "2d_convnet_batch_norm13a (Batch (None, None, None, 6 240         2d_convnet_layer13a[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "2d_convnet_layer13b (Conv2D)    (None, None, None, 6 32460       2d_convnet_batch_norm13a[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "2d_convnet_batch_norm13b (Batch (None, None, None, 6 240         2d_convnet_layer13b[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "2d_convnet_residual_block13 (Ad (None, None, None, 6 0           2d_convnet_batch_norm13b[0][0]   \n",
      "                                                                 2d_convnet_residual_block12[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "2d_convnet_layer14a (Conv2D)    (None, None, None, 6 32460       2d_convnet_residual_block13[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "2d_convnet_batch_norm14a (Batch (None, None, None, 6 240         2d_convnet_layer14a[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "2d_convnet_layer14b (Conv2D)    (None, None, None, 6 32460       2d_convnet_batch_norm14a[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "2d_convnet_batch_norm14b (Batch (None, None, None, 6 240         2d_convnet_layer14b[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "2d_convnet_residual_block14 (Ad (None, None, None, 6 0           2d_convnet_batch_norm14b[0][0]   \n",
      "                                                                 2d_convnet_residual_block13[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "2d_convnet_layer15a (Conv2D)    (None, None, None, 6 32460       2d_convnet_residual_block14[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "2d_convnet_batch_norm15a (Batch (None, None, None, 6 240         2d_convnet_layer15a[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "2d_convnet_layer15b (Conv2D)    (None, None, None, 6 32460       2d_convnet_batch_norm15a[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "2d_convnet_batch_norm15b (Batch (None, None, None, 6 240         2d_convnet_layer15b[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "2d_convnet_residual_block15 (Ad (None, None, None, 6 0           2d_convnet_batch_norm15b[0][0]   \n",
      "                                                                 2d_convnet_residual_block14[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "2d_convnet_layer16a (Conv2D)    (None, None, None, 6 32460       2d_convnet_residual_block15[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "2d_convnet_batch_norm16a (Batch (None, None, None, 6 240         2d_convnet_layer16a[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "2d_convnet_layer16b (Conv2D)    (None, None, None, 6 32460       2d_convnet_batch_norm16a[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "2d_convnet_batch_norm16b (Batch (None, None, None, 6 240         2d_convnet_layer16b[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "2d_convnet_residual_block16 (Ad (None, None, None, 6 0           2d_convnet_batch_norm16b[0][0]   \n",
      "                                                                 2d_convnet_residual_block15[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "2d_convnet_layer17a (Conv2D)    (None, None, None, 6 32460       2d_convnet_residual_block16[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "2d_convnet_batch_norm17a (Batch (None, None, None, 6 240         2d_convnet_layer17a[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "2d_convnet_layer17b (Conv2D)    (None, None, None, 6 32460       2d_convnet_batch_norm17a[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "2d_convnet_batch_norm17b (Batch (None, None, None, 6 240         2d_convnet_layer17b[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "2d_convnet_residual_block17 (Ad (None, None, None, 6 0           2d_convnet_batch_norm17b[0][0]   \n",
      "                                                                 2d_convnet_residual_block16[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "2d_convnet_layer18a (Conv2D)    (None, None, None, 6 32460       2d_convnet_residual_block17[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "2d_convnet_batch_norm18a (Batch (None, None, None, 6 240         2d_convnet_layer18a[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "2d_convnet_layer18b (Conv2D)    (None, None, None, 6 32460       2d_convnet_batch_norm18a[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "2d_convnet_batch_norm18b (Batch (None, None, None, 6 240         2d_convnet_layer18b[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "2d_convnet_residual_block18 (Ad (None, None, None, 6 0           2d_convnet_batch_norm18b[0][0]   \n",
      "                                                                 2d_convnet_residual_block17[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "2d_convnet_layer19a (Conv2D)    (None, None, None, 6 32460       2d_convnet_residual_block18[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "2d_convnet_batch_norm19a (Batch (None, None, None, 6 240         2d_convnet_layer19a[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "2d_convnet_layer19b (Conv2D)    (None, None, None, 6 32460       2d_convnet_batch_norm19a[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "2d_convnet_batch_norm19b (Batch (None, None, None, 6 240         2d_convnet_layer19b[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "2d_convnet_residual_block19 (Ad (None, None, None, 6 0           2d_convnet_batch_norm19b[0][0]   \n",
      "                                                                 2d_convnet_residual_block18[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "2d_convnet_layer20a (Conv2D)    (None, None, None, 6 32460       2d_convnet_residual_block19[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "2d_convnet_batch_norm20a (Batch (None, None, None, 6 240         2d_convnet_layer20a[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "2d_convnet_layer20b (Conv2D)    (None, None, None, 6 32460       2d_convnet_batch_norm20a[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "2d_convnet_batch_norm20b (Batch (None, None, None, 6 240         2d_convnet_layer20b[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "2d_convnet_residual_block20 (Ad (None, None, None, 6 0           2d_convnet_batch_norm20b[0][0]   \n",
      "                                                                 2d_convnet_residual_block19[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "2d_convnet_layer21a (Conv2D)    (None, None, None, 6 32460       2d_convnet_residual_block20[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "2d_convnet_batch_norm21a (Batch (None, None, None, 6 240         2d_convnet_layer21a[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "2d_convnet_layer21b (Conv2D)    (None, None, None, 6 32460       2d_convnet_batch_norm21a[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "2d_convnet_batch_norm21b (Batch (None, None, None, 6 240         2d_convnet_layer21b[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "2d_convnet_residual_block21 (Ad (None, None, None, 6 0           2d_convnet_batch_norm21b[0][0]   \n",
      "                                                                 2d_convnet_residual_block20[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "2d_convnet_layer22a (Conv2D)    (None, None, None, 6 32460       2d_convnet_residual_block21[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "2d_convnet_batch_norm22a (Batch (None, None, None, 6 240         2d_convnet_layer22a[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "2d_convnet_layer22b (Conv2D)    (None, None, None, 6 32460       2d_convnet_batch_norm22a[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "2d_convnet_batch_norm22b (Batch (None, None, None, 6 240         2d_convnet_layer22b[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "2d_convnet_residual_block22 (Ad (None, None, None, 6 0           2d_convnet_batch_norm22b[0][0]   \n",
      "                                                                 2d_convnet_residual_block21[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "2d_convnet_layer23a (Conv2D)    (None, None, None, 6 32460       2d_convnet_residual_block22[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "2d_convnet_batch_norm23a (Batch (None, None, None, 6 240         2d_convnet_layer23a[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "2d_convnet_layer23b (Conv2D)    (None, None, None, 6 32460       2d_convnet_batch_norm23a[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "2d_convnet_batch_norm23b (Batch (None, None, None, 6 240         2d_convnet_layer23b[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "2d_convnet_residual_block23 (Ad (None, None, None, 6 0           2d_convnet_batch_norm23b[0][0]   \n",
      "                                                                 2d_convnet_residual_block22[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "2d_convnet_layer24a (Conv2D)    (None, None, None, 6 32460       2d_convnet_residual_block23[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "2d_convnet_batch_norm24a (Batch (None, None, None, 6 240         2d_convnet_layer24a[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "2d_convnet_layer24b (Conv2D)    (None, None, None, 6 32460       2d_convnet_batch_norm24a[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "2d_convnet_batch_norm24b (Batch (None, None, None, 6 240         2d_convnet_layer24b[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "2d_convnet_residual_block24 (Ad (None, None, None, 6 0           2d_convnet_batch_norm24b[0][0]   \n",
      "                                                                 2d_convnet_residual_block23[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "2d_convnet_layer25a (Conv2D)    (None, None, None, 6 32460       2d_convnet_residual_block24[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "2d_convnet_batch_norm25a (Batch (None, None, None, 6 240         2d_convnet_layer25a[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "2d_convnet_layer25b (Conv2D)    (None, None, None, 6 32460       2d_convnet_batch_norm25a[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "2d_convnet_batch_norm25b (Batch (None, None, None, 6 240         2d_convnet_layer25b[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "2d_convnet_residual_block25 (Ad (None, None, None, 6 0           2d_convnet_batch_norm25b[0][0]   \n",
      "                                                                 2d_convnet_residual_block24[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "2d_convnet_layer26a (Conv2D)    (None, None, None, 6 32460       2d_convnet_residual_block25[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "2d_convnet_batch_norm26a (Batch (None, None, None, 6 240         2d_convnet_layer26a[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "2d_convnet_layer26b (Conv2D)    (None, None, None, 6 32460       2d_convnet_batch_norm26a[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "2d_convnet_batch_norm26b (Batch (None, None, None, 6 240         2d_convnet_layer26b[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "2d_convnet_residual_block26 (Ad (None, None, None, 6 0           2d_convnet_batch_norm26b[0][0]   \n",
      "                                                                 2d_convnet_residual_block25[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "2d_convnet_layer27a (Conv2D)    (None, None, None, 6 32460       2d_convnet_residual_block26[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "2d_convnet_batch_norm27a (Batch (None, None, None, 6 240         2d_convnet_layer27a[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "2d_convnet_layer27b (Conv2D)    (None, None, None, 6 32460       2d_convnet_batch_norm27a[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "2d_convnet_batch_norm27b (Batch (None, None, None, 6 240         2d_convnet_layer27b[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "2d_convnet_residual_block27 (Ad (None, None, None, 6 0           2d_convnet_batch_norm27b[0][0]   \n",
      "                                                                 2d_convnet_residual_block26[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "2d_convnet_layer28a (Conv2D)    (None, None, None, 6 32460       2d_convnet_residual_block27[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "2d_convnet_batch_norm28a (Batch (None, None, None, 6 240         2d_convnet_layer28a[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "2d_convnet_layer28b (Conv2D)    (None, None, None, 6 32460       2d_convnet_batch_norm28a[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "2d_convnet_batch_norm28b (Batch (None, None, None, 6 240         2d_convnet_layer28b[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "2d_convnet_residual_block28 (Ad (None, None, None, 6 0           2d_convnet_batch_norm28b[0][0]   \n",
      "                                                                 2d_convnet_residual_block27[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "2d_convnet_layer29a (Conv2D)    (None, None, None, 6 32460       2d_convnet_residual_block28[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "2d_convnet_batch_norm29a (Batch (None, None, None, 6 240         2d_convnet_layer29a[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "2d_convnet_layer29b (Conv2D)    (None, None, None, 6 32460       2d_convnet_batch_norm29a[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "2d_convnet_batch_norm29b (Batch (None, None, None, 6 240         2d_convnet_layer29b[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "2d_convnet_residual_block29 (Ad (None, None, None, 6 0           2d_convnet_batch_norm29b[0][0]   \n",
      "                                                                 2d_convnet_residual_block28[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "conv2d_181 (Conv2D)             (None, None, None, 2 122         2d_convnet_residual_block29[0][0]\n",
      "==================================================================================================\n",
      "Total params: 2,003,522\n",
      "Trainable params: 1,996,082\n",
      "Non-trainable params: 7,440\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# from tensorflow.keras import regularizers\n",
    "# def create_architecture(resid_layer2_window_size, resid_layer2_num_layers):\n",
    "#     \"\"\"\n",
    "#     Create the basic architecture. \n",
    "#     1d residual network followed by 2d residual network.\n",
    "\n",
    "#     :param resid_layer2_window_size: window size\n",
    "#     :type  resid_layer2_window_size: int\n",
    "#     :param resid_layer2_num_layers: number of layers\n",
    "#     :type  resid_layer2_num_layers: int\n",
    "#     :returns: training model\n",
    "#     :rtype:   tensorflow.python.keras.engine.training.Model\n",
    "#     \"\"\"\n",
    "\n",
    "#     input_tensor = tf.keras.Input(\n",
    "#         shape=(None, 20),\n",
    "#         name=\"input_layer\"\n",
    "#     )\n",
    "\n",
    "#     x = residual_conv_block(\n",
    "#         input_tensor,\n",
    "#         \"1d_convnet\",\n",
    "#         17,\n",
    "#         num_layers=6,\n",
    "#         regularizer=tf.keras.regularizers.l2(0.001)\n",
    "#     )\n",
    "\n",
    "#     x = OuterProduct(\n",
    "#     )(x)\n",
    "\n",
    "#     x = residual_conv_block(\n",
    "#         x,\n",
    "#         \"2d_convnet\",\n",
    "#         resid_layer2_window_size,\n",
    "#         num_layers=resid_layer2_num_layers,\n",
    "#         regularizer=tf.keras.regularizers.l2(0.001)\n",
    "#     )\n",
    "\n",
    "#     x = tf.keras.layers.Conv2D(\n",
    "#         2,\n",
    "#         1,\n",
    "#         activation='relu',\n",
    "#         padding='same',\n",
    "#         kernel_regularizer=tf.keras.regularizers.l2(0.001)\n",
    "#     )(x)\n",
    "\n",
    "# #     x = tf.keras.layers.Dropout(\n",
    "# #         0.5,\n",
    "# #         name=\"Drop-Out\"\n",
    "# #     )(x)\n",
    "\n",
    "#     model = tf.keras.models.Model(\n",
    "#         input_tensor,\n",
    "#         x\n",
    "#     )\n",
    "\n",
    "#     return model\n",
    "\n",
    "\n",
    "# third column is the number of feature maps\n",
    "model = create_architecture()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensorflow.python.keras.engine.training.Model"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.0"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ?tf.keras.layers.Conv2D\n",
    "6 / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint, LearningRateScheduler, \\\n",
    "    EarlyStopping, ReduceLROnPlateau, TensorBoard\n",
    "\n",
    "weight_path = \"best_weight/{}_weights.best.hdf5\".format('CNN2')\n",
    "\n",
    "checkpoint = ModelCheckpoint(\n",
    "    weight_path,\n",
    "    monitor='val_loss',\n",
    "    verbose=1,\n",
    "    save_best_only=True,\n",
    "    mode='min',\n",
    "    save_weights_only=True\n",
    ")\n",
    "\n",
    "tensorboard = TensorBoard(\n",
    "    log_dir='Logs',\n",
    "\n",
    "    # ValueError: If printing histograms, validation_data must be provided,\n",
    "    # and cannot be a generator.\n",
    "    # histogram_freq=5, # records activation histogram every n epoch\n",
    ")\n",
    "\n",
    "reduceLROnPlat = ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    factor=0.2,\n",
    "    patience=1,\n",
    "    verbose=1,\n",
    "    mode='min',\n",
    "    min_delta=0.0001,\n",
    "    cooldown=2,\n",
    "    min_lr=1e-7\n",
    ")\n",
    "\n",
    "\n",
    "def step_decay(epoch):\n",
    "    \"\"\"\n",
    "    Reduce learning rate after epochs.\n",
    "    \"\"\"\n",
    "\n",
    "    initial_lrate = 0.0001\n",
    "    drop = 0.5\n",
    "    epochs_drop = 10.0\n",
    "    lrate = initial_lrate * math.pow(drop, math.floor((1+epoch)/epochs_drop))\n",
    "    return lrate\n",
    "\n",
    "\n",
    "lrate = LearningRateScheduler(step_decay)  # can place this in call_backs_list\n",
    "\n",
    "early = EarlyStopping(\n",
    "    monitor=\"val_loss\",\n",
    "    # monitor='acc'\n",
    "    mode=\"min\",\n",
    "    verbose=2,\n",
    "    # training is interrupted when the monitor argument stops improving after n steps\n",
    "    patience=5\n",
    ")\n",
    "\n",
    "# callbacks_list = [checkpoint, early, reduceLROnPlat, tensorboard]\n",
    "\n",
    "# early, tensorboard\n",
    "callbacks_list = [checkpoint, ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-160-efcf112d4b3c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks_list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m )\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   2175\u001b[0m         \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2176\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2177\u001b[0;31m         initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   2178\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2179\u001b[0m   def evaluate_generator(self,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0mdo_validation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdo_validation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m       \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_test_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_make_train_function\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    698\u001b[0m           \u001b[0;31m# Training updates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    699\u001b[0m           updates = self.optimizer.get_updates(\n\u001b[0;32m--> 700\u001b[0;31m               params=self._collected_trainable_weights, loss=self.total_loss)\n\u001b[0m\u001b[1;32m    701\u001b[0m         \u001b[0;31m# Unconditional updates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    702\u001b[0m         \u001b[0mupdates\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_updates_for\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/keras/optimizers.py\u001b[0m in \u001b[0;36mget_updates\u001b[0;34m(self, loss, params)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mget_updates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m     \u001b[0mgrads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mstate_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massign_add\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/keras/optimizers.py\u001b[0m in \u001b[0;36mget_gradients\u001b[0;34m(self, loss, params)\u001b[0m\n\u001b[1;32m     81\u001b[0m           function not implemented).\n\u001b[1;32m     82\u001b[0m     \"\"\"\n\u001b[0;32m---> 83\u001b[0;31m     \u001b[0mgrads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgrads\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m       raise ValueError('An operation has `None` for gradient. '\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36mgradients\u001b[0;34m(loss, variables)\u001b[0m\n\u001b[1;32m   3027\u001b[0m   \"\"\"\n\u001b[1;32m   3028\u001b[0m   return gradients_module.gradients(\n\u001b[0;32m-> 3029\u001b[0;31m       loss, variables, colocate_gradients_with_ops=True)\n\u001b[0m\u001b[1;32m   3030\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3031\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py\u001b[0m in \u001b[0;36mgradients\u001b[0;34m(ys, xs, grad_ys, name, colocate_gradients_with_ops, gate_gradients, aggregation_method, stop_gradients)\u001b[0m\n\u001b[1;32m    628\u001b[0m   \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_default_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mutation_lock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    629\u001b[0m     return _GradientsHelper(ys, xs, grad_ys, name, colocate_gradients_with_ops,\n\u001b[0;32m--> 630\u001b[0;31m                             gate_gradients, aggregation_method, stop_gradients)\n\u001b[0m\u001b[1;32m    631\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    632\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py\u001b[0m in \u001b[0;36m_GradientsHelper\u001b[0;34m(ys, xs, grad_ys, name, colocate_gradients_with_ops, gate_gradients, aggregation_method, stop_gradients, src_graph)\u001b[0m\n\u001b[1;32m    803\u001b[0m                 \u001b[0mout_grads\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloop_state\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mZerosLike\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    804\u001b[0m               \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 805\u001b[0;31m                 \u001b[0mout_grads\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontrol_flow_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mZerosLikeOutsideLoop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    806\u001b[0m           \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"_grad\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    807\u001b[0m             \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/control_flow_ops.py\u001b[0m in \u001b[0;36mZerosLikeOutsideLoop\u001b[0;34m(op, index)\u001b[0m\n\u001b[1;32m   1467\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol_dependencies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpivot\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1468\u001b[0m           return array_ops.zeros(\n\u001b[0;32m-> 1469\u001b[0;31m               gen_resource_variable_ops.variable_shape(switch_val))\n\u001b[0m\u001b[1;32m   1470\u001b[0m       \u001b[0mzeros_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mswitch_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1471\u001b[0m       \u001b[0;31m# Ensure ops created within array_ops.zeros are dominated by switch in\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/array_ops.py\u001b[0m in \u001b[0;36mzeros\u001b[0;34m(shape, dtype, name)\u001b[0m\n\u001b[1;32m   1561\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shape_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1562\u001b[0m       \u001b[0mshape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Ensure it's a vector\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1563\u001b[0;31m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfill\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzero\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1564\u001b[0m   \u001b[0;32massert\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_dtype\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1565\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/gen_array_ops.py\u001b[0m in \u001b[0;36mfill\u001b[0;34m(dims, value, name)\u001b[0m\n\u001b[1;32m   2977\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0m_ctx\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_eager_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_eager\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2978\u001b[0m     _, _, _op = _op_def_lib._apply_op_helper(\n\u001b[0;32m-> 2979\u001b[0;31m         \"Fill\", dims=dims, value=value, name=name)\n\u001b[0m\u001b[1;32m   2980\u001b[0m     \u001b[0m_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2981\u001b[0m     \u001b[0m_inputs_flat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[0;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    785\u001b[0m         op = g.create_op(op_type_name, inputs, output_types, name=scope,\n\u001b[1;32m    786\u001b[0m                          \u001b[0minput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattr_protos\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 787\u001b[0;31m                          op_def=op_def)\n\u001b[0m\u001b[1;32m    788\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0moutput_structure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_stateful\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    789\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    486\u001b[0m                 \u001b[0;34m'in a future version'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'after %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    487\u001b[0m                 instructions)\n\u001b[0;32m--> 488\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    489\u001b[0m     return tf_decorator.make_decorator(func, new_func, 'deprecated',\n\u001b[1;32m    490\u001b[0m                                        _add_deprecated_arg_notice_to_docstring(\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mcreate_op\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   3273\u001b[0m           \u001b[0moriginal_op\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_default_original_op\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3274\u001b[0m           op_def=op_def)\n\u001b[0;32m-> 3275\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_op_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompute_device\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcompute_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3276\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3277\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_create_op_helper\u001b[0;34m(self, op, compute_device)\u001b[0m\n\u001b[1;32m   3388\u001b[0m       \u001b[0mall_colocation_groups\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3389\u001b[0m       \u001b[0;32mfor\u001b[0m \u001b[0mcolocation_op\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_colocation_stack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpeek_objs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3390\u001b[0;31m         \u001b[0mall_colocation_groups\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolocation_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolocation_groups\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3391\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcolocation_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3392\u001b[0m           if (op.device and pydev.canonical_name(op.device) !=\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mcolocation_groups\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1859\u001b[0m     ]\n\u001b[1;32m   1860\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1861\u001b[0;31m       \u001b[0mclass_attr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_attr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"_class\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1862\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1863\u001b[0m       \u001b[0;31m# This op has no explicit colocation group, so it is itself its\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mget_attr\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   2326\u001b[0m       \u001b[0;31m# Convert to ValueError for backwards compatibility.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2327\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2328\u001b[0;31m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattr_value_pb2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAttrValue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2329\u001b[0m     \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mParseFromString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2330\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.compile(\n",
    "#     optimizer=tf.train.AdamOptimizer(0.001),\n",
    "    optimizer=\"adam\",\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    sample_weight_mode=\"temporal\",\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "history = model.fit_generator(\n",
    "    aa_generator(train_aa_dict, train_cmap_dict),\n",
    "    validation_data=aa_generator(valid_aa_dict, valid_cmap_dict),\n",
    "    steps_per_epoch=3, \n",
    "    epochs=2,\n",
    "    validation_steps=3,\n",
    "    callbacks=callbacks_list\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "1/1 [==============================] - 0s 78ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.073815941810608, 0.8060165047645569]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_input = devtest_aa_dict['1b8k']\n",
    "test_output = devtest_cmap_dict['1b8k']\n",
    "\n",
    "test_input = np.reshape(test_input, (1,) + test_input.shape)\n",
    "\n",
    "test_output = np.reshape(test_output, (1,) + test_output.shape + (1,))\n",
    "\n",
    "# outputs loss and accuracy\n",
    "model.evaluate(test_input, test_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'1b8k': array([[0., 0., 0., ..., 0., 0., 1.],\n",
       "        [1., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]]),\n",
       " '1bg6': array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [1., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 1., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]]),\n",
       " '1bx7': array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [1., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]]),\n",
       " '1cb8': array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]]),\n",
       " '1cc8': array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [1., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]]),\n",
       " '1dcs': array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 1., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [1., 0., 0., ..., 0., 0., 0.]]),\n",
       " '1fkm': array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]]),\n",
       " '1ft5': array([[1., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 1., ..., 0., 0., 0.],\n",
       "        [1., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]]),\n",
       " '1gak': array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 1., ..., 0., 0., 0.],\n",
       "        [0., 0., 1., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]]),\n",
       " '1gci': array([[1., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [1., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]]),\n",
       " '1gjw': array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 1., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]]),\n",
       " '1gpr': array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [1., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]]),\n",
       " '1gs5': array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [1., 0., 0., ..., 0., 0., 0.]]),\n",
       " '1gsm': array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]]),\n",
       " '1gui': array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]]),\n",
       " '1gwm': array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 1., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]]),\n",
       " '1hk8': array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]]),\n",
       " '1j3a': array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]]),\n",
       " '1j77': array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]])}"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "devtest_aa_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1831be8cc0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pl.plot_loss(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEWCAYAAACXGLsWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nnZtM23zrIAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1834851f60>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.clf()\n",
    "pl.plot_acc(\n",
    "    history, \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'acc': [0.6589804490407308, 0.6804484128952026],\n",
       " 'loss': [3.158297856648763, 2.313175598780314],\n",
       " 'val_acc': [0.6771519780158997, 0.774169921875],\n",
       " 'val_loss': [1.0190336108207703, 1.1663833856582642]}"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history#['acc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# !tensorboard --logdir=Logs\n",
    "# http://localhost:6006/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import plot_model\n",
    "\n",
    "\"\"\"\n",
    "need to create a bash script that sets up\n",
    "the modeling (creating directories, etc)\n",
    "\n",
    "can place this in preprocess.sh, but rename the file\n",
    "\"\"\"\n",
    "plot_model(\n",
    "    model, \n",
    "    show_shapes=True, \n",
    "    show_layer_names=True,\n",
    "    to_file='model.png',\n",
    "    rankdir='TB'\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
