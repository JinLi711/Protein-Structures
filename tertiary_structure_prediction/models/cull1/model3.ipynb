{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'primary_model' from '../model_functions/primary_model.py'>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "sys.path.insert(0, '../model_functions')\n",
    "import primary_model as pm\n",
    "import importlib\n",
    "importlib.reload(pm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_path = \"../../data/cull%i/model_data/\" % 1\n",
    "\n",
    "devtest_aa_dict = np.load(data_path + 'devtest_aa_dict.npy')[()]\n",
    "devtest_cmap_dict = np.load(data_path + 'devtest_cmap_dict.npy')[()]\n",
    "train_aa_dict = np.load(data_path + 'train_aa_dict.npy')[()]\n",
    "train_cmap_dict = np.load(data_path + 'train_cmap_dict.npy')[()]\n",
    "valid_aa_dict = np.load(data_path + 'valid_aa_dict.npy')[()]\n",
    "valid_cmap_dict = np.load(data_path + 'valid_cmap_dict.npy')[()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = pm.create_architecture(3, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_layer (InputLayer)        (None, None, 20)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "1d_convnet_layer1a (Conv1D)     (None, None, 20)     6820        input_layer[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "1d_convnet_batch_norm1a (BatchN (None, None, 20)     80          1d_convnet_layer1a[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "1d_convnet_layer1b (Conv1D)     (None, None, 20)     6820        1d_convnet_batch_norm1a[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "1d_convnet_batch_norm1b (BatchN (None, None, 20)     80          1d_convnet_layer1b[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "1d_convnet_residual_block1 (Add (None, None, 20)     0           1d_convnet_batch_norm1b[0][0]    \n",
      "                                                                 input_layer[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "1d_convnet_layer2a (Conv1D)     (None, None, 20)     6820        1d_convnet_residual_block1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "1d_convnet_batch_norm2a (BatchN (None, None, 20)     80          1d_convnet_layer2a[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "1d_convnet_layer2b (Conv1D)     (None, None, 20)     6820        1d_convnet_batch_norm2a[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "1d_convnet_batch_norm2b (BatchN (None, None, 20)     80          1d_convnet_layer2b[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "1d_convnet_residual_block2 (Add (None, None, 20)     0           1d_convnet_batch_norm2b[0][0]    \n",
      "                                                                 1d_convnet_residual_block1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "1d_convnet_layer3a (Conv1D)     (None, None, 20)     6820        1d_convnet_residual_block2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "1d_convnet_batch_norm3a (BatchN (None, None, 20)     80          1d_convnet_layer3a[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "1d_convnet_layer3b (Conv1D)     (None, None, 20)     6820        1d_convnet_batch_norm3a[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "1d_convnet_batch_norm3b (BatchN (None, None, 20)     80          1d_convnet_layer3b[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "1d_convnet_residual_block3 (Add (None, None, 20)     0           1d_convnet_batch_norm3b[0][0]    \n",
      "                                                                 1d_convnet_residual_block2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "outer_product_1 (OuterProduct)  (None, None, None, 6 0           1d_convnet_residual_block3[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "2d_convnet_layer1a (Conv2D)     (None, None, None, 6 32460       outer_product_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "2d_convnet_batch_norm1a (BatchN (None, None, None, 6 240         2d_convnet_layer1a[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "2d_convnet_layer1b (Conv2D)     (None, None, None, 6 32460       2d_convnet_batch_norm1a[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "2d_convnet_batch_norm1b (BatchN (None, None, None, 6 240         2d_convnet_layer1b[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "2d_convnet_residual_block1 (Add (None, None, None, 6 0           2d_convnet_batch_norm1b[0][0]    \n",
      "                                                                 outer_product_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "2d_convnet_layer2a (Conv2D)     (None, None, None, 6 32460       2d_convnet_residual_block1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "2d_convnet_batch_norm2a (BatchN (None, None, None, 6 240         2d_convnet_layer2a[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "2d_convnet_layer2b (Conv2D)     (None, None, None, 6 32460       2d_convnet_batch_norm2a[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "2d_convnet_batch_norm2b (BatchN (None, None, None, 6 240         2d_convnet_layer2b[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "2d_convnet_residual_block2 (Add (None, None, None, 6 0           2d_convnet_batch_norm2b[0][0]    \n",
      "                                                                 2d_convnet_residual_block1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "2d_convnet_layer3a (Conv2D)     (None, None, None, 6 32460       2d_convnet_residual_block2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "2d_convnet_batch_norm3a (BatchN (None, None, None, 6 240         2d_convnet_layer3a[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "2d_convnet_layer3b (Conv2D)     (None, None, None, 6 32460       2d_convnet_batch_norm3a[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "2d_convnet_batch_norm3b (BatchN (None, None, None, 6 240         2d_convnet_layer3b[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "2d_convnet_residual_block3 (Add (None, None, None, 6 0           2d_convnet_batch_norm3b[0][0]    \n",
      "                                                                 2d_convnet_residual_block2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, None, None, 2 122         2d_convnet_residual_block3[0][0] \n",
      "==================================================================================================\n",
      "Total params: 237,722\n",
      "Trainable params: 236,762\n",
      "Non-trainable params: 960\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(\n",
    "        optimizer=\"adam\",\n",
    "        loss=\"sparse_categorical_crossentropy\",\n",
    "        sample_weight_mode=\"temporal\",\n",
    "        metrics=['accuracy']\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jinli/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:112: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "4/5 [=======================>......] - ETA: 3s - loss: 4.5926 - acc: 0.5902\n",
      "Epoch 00001: val_loss improved from inf to 5.18052, saving model to best_weight/Double_Resid_Network_weights.best.hdf5\n",
      "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x182d332198>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "5/5 [==============================] - 23s 5s/step - loss: 4.4899 - acc: 0.6004 - val_loss: 5.1805 - val_acc: 0.5830\n",
      "Epoch 2/2\n",
      "4/5 [=======================>......] - ETA: 10s - loss: 3.7129 - acc: 0.6658\n",
      "Epoch 00002: val_loss did not improve from 5.18052\n",
      "\n",
      "Epoch 00002: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "5/5 [==============================] - 43s 9s/step - loss: 3.7026 - acc: 0.6559 - val_loss: 5.2892 - val_acc: 0.5433\n"
     ]
    }
   ],
   "source": [
    "history = model.fit_generator(\n",
    "        pm.aa_generator(train_aa_dict, train_cmap_dict),\n",
    "        validation_data=pm.aa_generator(valid_aa_dict, valid_cmap_dict),\n",
    "        steps_per_epoch=5, \n",
    "        epochs=2,\n",
    "        validation_steps=1,\n",
    "        callbacks=pm.callbacks_list\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
